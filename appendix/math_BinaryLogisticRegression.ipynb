{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ1aQ0VXoJZY"
   },
   "source": [
    "# ロジスティック回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAqTWW3L91e4"
   },
   "source": [
    "## 二値分類問題（ベルヌーイ分布）における対数尤度の導出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1ji05uh9wtg"
   },
   "source": [
    "目的変数を $y^{(n)} \\in \\{0, 1\\}$ で表すとする。  \n",
    "すると、あるデータ点 ${\\bf x}^{(n)}$ のラベルが 1 / 0  である確率は、下記のような事後確率で表現することができる。\n",
    "\n",
    "$$\n",
    "p(y^{(n)} = 1|{\\bf x}^{(n)}) = \\tilde{Y}({\\bf x}^{(n)};{\\bf w})  \\\\\n",
    "p(y^{(n)} = 0|{\\bf x}^{(n)}) = 1 - \\tilde{Y}({\\bf x}^{(n)};{\\bf w}) \n",
    "$$\n",
    "\n",
    "これをべき乗を使ったトリックで、下記のような一つの式でまとめて表すことができる。\n",
    "\n",
    "$$\n",
    "p(y^{(n)}|{\\bf x}^{(n)}) = \\{\\tilde{Y}({\\bf x}^{(n)};{\\bf w})\\}^{y^{(n)}} \\{1 - \\tilde{Y}({\\bf x}^{(n)};{\\bf w})\\}^{1 - y^(n)} \n",
    "$$\n",
    "\n",
    "尤度は上式で表されるような確率密度の積で表すことができたので、\n",
    "\n",
    "$$\n",
    "P = \\prod^N_{n=1} { p(y^{(n)}|{\\bf x}^{(n)}) } = \\prod^N_{n=1} { \\{\\tilde{Y}({\\bf x}^{(n)};{\\bf w})\\}^{y^{(n)}} \\{1 - \\tilde{Y}({\\bf x}^{(n)};{\\bf w})\\}^{1 - y^{(n)}} }\n",
    "$$\n",
    "\n",
    "対数尤度を取ると、\n",
    "\n",
    "$$\n",
    "\\ln P = \\sum^N_{n=1} { y^{(n)} \\ln \\tilde{Y}({\\bf x}^{(n)};{\\bf w}) + (1 - y^{(n)}) \\ln (1 - \\tilde{Y} ({\\bf x}^{(n)};{\\bf w}) ) } \\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9meFmQuS2EkJ"
   },
   "source": [
    "## 確率的勾配法による対数尤度最大化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WalBWuEz-2uG"
   },
   "source": [
    "### 連鎖律の適用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2C8m03R5oM3m"
   },
   "source": [
    "記載の簡単化のため、$\\sigma$ をシグモイド関数とし、$z_n = \\tilde{Y}({\\bf x}^{(n)};{\\bf w}) = \\sigma ({\\bf w^T x})$ とすると、以下のように記載できる。\n",
    "\n",
    "$$\n",
    "\\ln P = \\sum^N_{n=1} { y^{(n)} \\ln z_n + (1 - y^{(n)}) \\ln (1 - z_n ) } \\tag{2}\n",
    "$$\n",
    "\n",
    "\n",
    "確率的勾配法では、データの一部に対して勾配 ${\\frac{\\partial \\ln P}{\\partial {\\bf w}}}$ を計算し、学習率 $\\eta$ で減衰させた値 $\\eta \\frac{\\partial \\ln P}{\\partial {\\bf w}}$ を現在の重み${\\bf w}$に対して加えていくことで、現在よりも良い解 ${\\bf w}^{new}$ を得る。  \n",
    "これを式で表すと以下の通り。\n",
    "\n",
    "$$\n",
    "{\\bf w}^{new} \\leftarrow {\\bf w} + \\eta \\frac{\\partial \\ln P}{\\partial {\\bf w}} \\tag{3}\n",
    "$$\n",
    "\n",
    "${\\bf w}$ の $m$ 番目の要素 $w_m$ を考えると、上式同様、\n",
    "\n",
    "$$\n",
    "w_m^{new} \\leftarrow w_m + \\eta \\frac{\\partial \\ln P}{\\partial {w_m}} \\tag{4}\n",
    "$$\n",
    "\n",
    "と表すことができるため、$w_m^{new}$ は、対数尤度の勾配 $\\frac{\\partial \\ln P}{\\partial {w_m}}$ が求まれば算出できる。ただし、$\\ln P$ は $z_n$ の関数であり、直接 $w_m$ で微分することは難しいため、以下のように連鎖律（chain rule）を適用すると、下記にように表すことができる。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ln P}{\\partial {w_m}} = \n",
    "\\frac{\\partial \\ln P}{\\partial z_n} \\frac{\\partial z_n}{\\partial w_m} \\tag{5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNQx6HO-2cKl"
   },
   "source": [
    "### $\\frac{\\partial \\ln P}{\\partial z_n}$ の導出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CP-oqysj26VL"
   },
   "source": [
    "対数関数の微分: $(\\log x)' = \\frac{1}{x}$ を用いると、$\\ln P$ の $z_n$ に関する微分は式(2) を用いて下記のように表すことができる。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ln P}{\\partial z_n} = \\sum_{n=1}^N { \\{ \\frac{y^{(n)}}{z_n} - \\frac{1-y^{(n)}}{1-z_n}\\} } \\tag{6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yp3yPjDX2wqk"
   },
   "source": [
    "### $\\frac{\\partial z_n}{\\partial w_m}$ の導出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKrL1vuh2gmV"
   },
   "source": [
    "シグモイド関数の微分: $\\sigma ' =  \\sigma(1- \\sigma)$ を用いると、$z_n = \\sigma ({\\bf w^T x})$ の $w_m$ に関する偏微分は下記のように表すことができる。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z_n}{\\partial w_m} = z_n(1-z_n)[x_n]_m \\tag{7}\n",
    "$$\n",
    "\n",
    "ただし、$[x_n]_m$ は、n個目のデータのm番目の説明変数である。（0番目の説明変数はバイアス項: 1 とする）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BJKTOAx4dkv"
   },
   "source": [
    "### $\\frac{\\partial \\ln P}{\\partial {w_m}}$ の導出から ${ w_m}^{new}$ の導出まで"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_sJjaKC44M8"
   },
   "source": [
    "式(6), (7) から、$\\ln P$ の $w_m$ に関する勾配は、下記のように求まる。\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "\\frac{\\partial \\ln P}{\\partial {w_m}} \n",
    "&= \\frac{\\partial \\ln P}{\\partial z_n} \\frac{\\partial z_n}{\\partial w_m} \\\\\n",
    "&= \\sum_{n=1}^N { \\{ \\frac{y^{(n)}}{z_n} - \\frac{1-y^{(n)}}{1-z_n}\\} z_n(1-z_n)[x_n]_m } \\\\\n",
    "&= \\sum_{n=1}^N{\\{ y^{(n)}(1-z_n) - z_n(1-y^{(n)}) \\} [x_n]_m} \\\\\n",
    "&= \\sum_{n=1}^N{\\{ y^{(n)} - z_n \\} [x_n]_m}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "従って、${w_m}^{new}$ は下記の通り。\n",
    "\n",
    "$$\n",
    "{w_m}^{new} = {w_m} + \\eta \\sum_{n=1}^N{\\{ y^{(n)} - z_n \\} [x_n]_m}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2_BinaryLogisticRegression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
